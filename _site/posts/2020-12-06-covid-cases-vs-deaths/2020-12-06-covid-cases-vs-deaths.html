<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Art Steinmetz">
<meta name="dcterms.date" content="2020-12-06">
<meta name="description" content="Estimate the average lag between a positive COVID-19 case and a death.">

<title>Outsider Data Science - Covid Cases vs.&nbsp;Deaths</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Outsider Data Science</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">Art Steinmetz</span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Covid Cases vs.&nbsp;Deaths</h1>
  <div class="quarto-categories">
    <div class="quarto-category">ggplot2</div>
    <div class="quarto-category">tidymodels</div>
    <div class="quarto-category">tidyverse</div>
    <div class="quarto-category">COVID</div>
  </div>
  </div>

<div>
  <div class="description">
    Estimate the average lag between a positive COVID-19 case and a death.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Art Steinmetz </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 6, 2020</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<link href="../../rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet">
<script src="../../rmarkdown-libs/anchor-sections/anchor-sections.js"></script>
<section id="introduction" class="level1">
<h1>
Introduction
</h1>
<p>
I have a macabre fascination with tracking the course of the COVID-19 pandemic. I suspect there are two reasons for this. One, by delving into the numbers I imagine I have some control over this thing. Second, it feels like lighting a candle to show that science can reveal truth at a time when the darkness of anti-science is creeping across the land.
</p>
<p>
The purpose of this project is, as usual, twofold. First, to explore an interesting data science question and, second, to explore some techniques and packages in the R universe. We will be looking at the relationship of COVID-19 cases to mortality. What is the lag between a positive case and a death? How does that vary among states? How has it varied as the pandemic has progressed? This is an interesting project because is combines elements of time series forecasting and dependent variable prediction.
</p>
<p>
I have been thinking about how to measure mortality lags for a while now. What prompted to do a write-up was discovering a new function in Matt Dancho’s <code>timetk</code> package, <code>tk_augment_lags</code>, which makes short work of building multiple lags. Not too long ago, managing models for multiple lags and multiple states would have been a bit messy. The emerging “tidy models” framework from RStudio using “list columns” is immensely powerful for this sort of thing. It’s great to reduce so much analysis into so few lines of code.
</p>
<p>
This was an exciting project because I got some validation of my approach. I am NOT an epidemiologist or a professional data scientist. None of the results I show here should be considered authoritative. Still, while I was working on this project I saw <a href="https://www.wsj.com/livecoverage/covid-2020-12-02/card/kdSg0ILBfalJHzXvX0bF">this article</a> in the “Wall Street Journal” which referenced the work by <a href="https://epi.washington.edu/faculty/bedford-trevor">Dr.&nbsp;Trevor Bedford</a>, an epidemiologist at the University of Washington. He took the same approach I did and got about the same result.
</p>
</section>
<section id="aquire-and-clean-data" class="level1">
<h1>
Aquire and Clean Data
</h1>
<p>
There is no shortage of data to work with. Here we will use the NY Times COVID tracking data set which is updated daily. The package <code>covid19nytimes</code> lets us refresh the data on demand.
</p>
<pre class="sourceCode r code-with-copy"><code># correlate deaths and cases by state
library(tidyverse)
library(covid19nytimes)
library(timetk)
library(lubridate)
library(broom)
library(knitr)

# source https://github.com/nytimes/covid-19-data.git
us_states_long &lt;- covid19nytimes::refresh_covid19nytimes_states()

# if link is broken
#load("../data/us_states_long.rdata")

# use data from November 15 to stay consistent with text narrative
cutoff_start &lt;- as.Date("2020-03-15") # not widespread enough until then
cutoff_end &lt;- max(us_states_long$date) -7 # discard last week since there are reporting lags

us_states_long &lt;- us_states_long %&gt;% filter(date &gt;= cutoff_start)
us_states_long &lt;- us_states_long %&gt;% filter(date &lt;= cutoff_end)
# Remove tiny territories
territories &lt;- c("Guam","Northern Mariana Islands")
us_states_long &lt;- us_states_long %&gt;% filter(!(location %in% territories))
save(us_states_long,file="us_states_long.rdata")
us_states_long %&gt;% head() %&gt;% kable()</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>

<table class="table">
<thead>
<tr class="header">
<th align="left">
date
</th>
<th align="left">
location
</th>
<th align="left">
location_type
</th>
<th align="left">
location_code
</th>
<th align="left">
location_code_type
</th>
<th align="left">
data_type
</th>
<th align="right">
value
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">
2020-11-28
</td>
<td align="left">
Alabama
</td>
<td align="left">
state
</td>
<td align="left">
01
</td>
<td align="left">
fips_code
</td>
<td align="left">
cases_total
</td>
<td align="right">
244993
</td>
</tr>
<tr class="even">
<td align="left">
2020-11-28
</td>
<td align="left">
Alabama
</td>
<td align="left">
state
</td>
<td align="left">
01
</td>
<td align="left">
fips_code
</td>
<td align="left">
deaths_total
</td>
<td align="right">
3572
</td>
</tr>
<tr class="odd">
<td align="left">
2020-11-28
</td>
<td align="left">
Alaska
</td>
<td align="left">
state
</td>
<td align="left">
02
</td>
<td align="left">
fips_code
</td>
<td align="left">
cases_total
</td>
<td align="right">
31279
</td>
</tr>
<tr class="even">
<td align="left">
2020-11-28
</td>
<td align="left">
Alaska
</td>
<td align="left">
state
</td>
<td align="left">
02
</td>
<td align="left">
fips_code
</td>
<td align="left">
deaths_total
</td>
<td align="right">
115
</td>
</tr>
<tr class="odd">
<td align="left">
2020-11-28
</td>
<td align="left">
Arizona
</td>
<td align="left">
state
</td>
<td align="left">
04
</td>
<td align="left">
fips_code
</td>
<td align="left">
cases_total
</td>
<td align="right">
322774
</td>
</tr>
<tr class="even">
<td align="left">
2020-11-28
</td>
<td align="left">
Arizona
</td>
<td align="left">
state
</td>
<td align="left">
04
</td>
<td align="left">
fips_code
</td>
<td align="left">
deaths_total
</td>
<td align="right">
6624
</td>
</tr>
</tbody>

</table>
<p>
The NY Times data is presented in a “long” format. When we start modeling, long will suit us well but first we have to add features to help us and that will require <code>pivot</code>ing to wide, adding features and then back to long. The daily data is so irregular the first features we will add are 7-day moving averages to smooth the series. We’ll also do a nation-level analysis first so we aggregate the state data as well.
</p>
<pre class="sourceCode r code-with-copy"><code># Create rolling average changes
# pivot wider
# this will also be needed when we create lags
us_states &lt;- us_states_long %&gt;%
  # discard dates before cases were tracked.
  filter(date &gt; as.Date("2020-03-01")) %&gt;% 
  pivot_wider(names_from="data_type",values_from="value") %&gt;% 
  rename(state=location) %&gt;%
  select(date,state,cases_total,deaths_total) %&gt;%
  mutate(state = as_factor(state)) %&gt;% 
  arrange(state,date) %&gt;% 
  group_by(state) %&gt;%
  #smooth the data with 7 day moving average
  mutate(cases_7day = (cases_total - lag(cases_total,7))/7) %&gt;%
  mutate(deaths_7day = (deaths_total - lag(deaths_total,7))/7) %&gt;%
  {.}

# national analysis
# ----------------------------------------------
# aggregate state to national
us &lt;- us_states %&gt;%
  group_by(date) %&gt;% 
  summarize(across(.cols=where(is.double),
                   .fns = function(x)sum(x,na.rm = T),
                   .names="{.col}"))

us[10:20,] %&gt;% kable()</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>

<table class="table">
<thead>
<tr class="header">
<th align="left">
date
</th>
<th align="right">
cases_total
</th>
<th align="right">
deaths_total
</th>
<th align="right">
cases_7day
</th>
<th align="right">
deaths_7day
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">
2020-03-24
</td>
<td align="right">
53906
</td>
<td align="right">
784
</td>
<td align="right">
6857.571
</td>
<td align="right">
95.28571
</td>
</tr>
<tr class="even">
<td align="left">
2020-03-25
</td>
<td align="right">
68540
</td>
<td align="right">
1053
</td>
<td align="right">
8599.714
</td>
<td align="right">
127.28571
</td>
</tr>
<tr class="odd">
<td align="left">
2020-03-26
</td>
<td align="right">
85521
</td>
<td align="right">
1352
</td>
<td align="right">
10448.571
</td>
<td align="right">
162.85714
</td>
</tr>
<tr class="even">
<td align="left">
2020-03-27
</td>
<td align="right">
102847
</td>
<td align="right">
1769
</td>
<td align="right">
12121.286
</td>
<td align="right">
213.14286
</td>
</tr>
<tr class="odd">
<td align="left">
2020-03-28
</td>
<td align="right">
123907
</td>
<td align="right">
2299
</td>
<td align="right">
14199.143
</td>
<td align="right">
277.00000
</td>
</tr>
<tr class="even">
<td align="left">
2020-03-29
</td>
<td align="right">
142426
</td>
<td align="right">
2717
</td>
<td align="right">
15625.714
</td>
<td align="right">
322.85714
</td>
</tr>
<tr class="odd">
<td align="left">
2020-03-30
</td>
<td align="right">
163893
</td>
<td align="right">
3367
</td>
<td align="right">
17202.429
</td>
<td align="right">
398.42857
</td>
</tr>
<tr class="even">
<td align="left">
2020-03-31
</td>
<td align="right">
188320
</td>
<td align="right">
4302
</td>
<td align="right">
19202.000
</td>
<td align="right">
502.57143
</td>
</tr>
<tr class="odd">
<td align="left">
2020-04-01
</td>
<td align="right">
215238
</td>
<td align="right">
5321
</td>
<td align="right">
20956.857
</td>
<td align="right">
609.71429
</td>
</tr>
<tr class="even">
<td align="left">
2020-04-02
</td>
<td align="right">
244948
</td>
<td align="right">
6537
</td>
<td align="right">
22775.286
</td>
<td align="right">
740.71429
</td>
</tr>
<tr class="odd">
<td align="left">
2020-04-03
</td>
<td align="right">
277264
</td>
<td align="right">
7927
</td>
<td align="right">
24916.714
</td>
<td align="right">
879.71429
</td>
</tr>
</tbody>

</table>
</section>
<section id="exploratory-data-analysis" class="level1">
<h1>
Exploratory Data Analysis
</h1>
<p>
We might be tempted to simply regress deaths vs.&nbsp;cases but a scatter plot shows us that would not be satisfactory. As it turns out, the relationship of cases and deaths is strongly conditioned on date. This reflects the declining mortality rate as we have come to better understand the disease.
</p>
<pre class="sourceCode r code-with-copy"><code># does a simple scatterplot tell us anything 
# about the relationship of deaths to cases? No.
us %&gt;% 
  ggplot(aes(deaths_7day,cases_7day)) + geom_point() +
  labs(title = "Not Useful",
       caption = "Source: NY Times, Arthur Steinmetz")</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/silly plot-1.png" width="672">
</p>
<p>
We can get much more insight plotting smoothed deaths and cases over time. It is generally bad form to use two different y axes on a single plot but but this example adds insight. A couple of observations are obvious. First when cases start to rise, deaths follow with a lag. Second, we have had three spikes in cases so far and in each successive instance the mortality has risen by a smaller amount. This suggests that, thankfully, we are getting better at treating this disease. It is NOT a function of increased testing because <a href="http://91-divoc.com/pages/covid-visualization/?chart=countries&amp;highlight=United%20States&amp;show=highlight-only&amp;y=highlight&amp;scale=linear&amp;data=testPositivity-daily-7&amp;data-source=merged&amp;xaxis=right-12wk#countries">positivity rates</a> have not been falling.
</p>
<pre class="sourceCode r code-with-copy"><code>#visualize the relationship between rolling average of weekly cases and deaths
coeff &lt;- 30
us %&gt;% 
  ggplot(aes(date,cases_7day)) + geom_line(color="orange") +
  theme(legend.position = "none") +
  geom_line(aes(x=date,y=deaths_7day*coeff),color="red") +
  scale_y_continuous(labels = scales::comma,
                     name = "Cases",
                     sec.axis = sec_axis(deaths_7day~./coeff,
                                         name="Deaths",
                                         labels = scales::comma)) +
  theme(
    axis.title.y = element_text(color = "orange", size=13),
    axis.title.y.right = element_text(color = "red", size=13)
  ) +
  labs(title =  "U.S. Cases vs. Deaths",
       subtitle = "7-Day Average",
       caption = "Source: NY Times, Arthur Steinmetz",
       x = "Date")</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/unnamed-chunk-2-1.png" width="672"> This illustrates a problem for any modeling we might do.It looks like the more cases surge, the less the impact on deaths. This is NOT a valid conclusion. A simple regression of deaths vs.&nbsp;cases and time shows the passage of time has more explanatory power than cases in predicting deaths so we have to take that into account.
</p>
<pre class="sourceCode r code-with-copy"><code># passage of time affects deaths more than cases
lm(deaths_7day~cases_7day+date,data=us) %&gt;% tidy()</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<pre><code>## # A tibble: 3 x 5
##   term           estimate   std.error statistic  p.value
##   &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept) 76542.      10054.           7.61 5.15e-13
## 2 cases_7day      0.00828     0.00112      7.41 1.86e-12
## 3 date           -4.11        0.547       -7.52 9.11e-13</code></pre>
</section>
<section id="build-some-models" class="level1">
<h1>
Build Some Models
</h1>
<p>
We’ll approach this by running regression models of deaths and varying lags (actually leads) of cases. We chose to lead deaths as opposed to lagging cases because it will allow us to make predictions about the future of deaths given cases today. We include the date as a variable as well. Once we’ve run regressions against each lead period, we’ll chose the lead period that has the best fit (R-Squared) to the data.
</p>
<p>
The requires a lot of leads and a lot of models. Fortunately, R provides the tools to make this work very simple and well organized. First we add new columns for each lead period using <code>timetk::tk_augment_lags</code>. This one function call does all the work but it only does lags so we have to futz with it a bit to get leads.
</p>
<p>
I chose to add forty days of leads. I don’t really think that long a lead is realistic and, given the pandemic has been around only nine months, there aren’t as many data points forty days ahead. Still, I want to see the behavior of the models. Once we have created the leads we remove any dates for which we don’t have led deaths.
</p>
<pre class="sourceCode r code-with-copy"><code>#create columns for deaths led 0 to 40 days ahead
max_lead &lt;- 40
us_lags &lt;- us %&gt;%
  # create lags by day
  tk_augment_lags(deaths_7day,.lags = 0:-max_lead,.names="auto")
  # fix names to remove minus sign
  names(us_lags) &lt;- names(us_lags) %&gt;% str_replace_all("lag-|lag","lead")

# use only case dates where we have complete future knowledge of deaths for all lead times.
us_lags &lt;- us_lags %&gt;% filter(date &lt; cutoff_end-max_lead)

us_lags[1:10,1:7] %&gt;% kable()</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>

<table class="table">
<colgroup>
<col width="11%">
<col width="12%">
<col width="13%">
<col width="11%">
<col width="12%">
<col width="18%">
<col width="18%">
</colgroup>
<thead>
<tr class="header">
<th align="left">
date
</th>
<th align="right">
cases_total
</th>
<th align="right">
deaths_total
</th>
<th align="right">
cases_7day
</th>
<th align="right">
deaths_7day
</th>
<th align="right">
deaths_7day_lead0
</th>
<th align="right">
deaths_7day_lead1
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">
2020-03-15
</td>
<td align="right">
3597
</td>
<td align="right">
68
</td>
<td align="right">
0.000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
</tr>
<tr class="even">
<td align="left">
2020-03-16
</td>
<td align="right">
4504
</td>
<td align="right">
91
</td>
<td align="right">
0.000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
</tr>
<tr class="odd">
<td align="left">
2020-03-17
</td>
<td align="right">
5903
</td>
<td align="right">
117
</td>
<td align="right">
0.000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
</tr>
<tr class="even">
<td align="left">
2020-03-18
</td>
<td align="right">
8342
</td>
<td align="right">
162
</td>
<td align="right">
0.000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
</tr>
<tr class="odd">
<td align="left">
2020-03-19
</td>
<td align="right">
12381
</td>
<td align="right">
212
</td>
<td align="right">
0.000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
</tr>
<tr class="even">
<td align="left">
2020-03-20
</td>
<td align="right">
17998
</td>
<td align="right">
277
</td>
<td align="right">
0.000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
</tr>
<tr class="odd">
<td align="left">
2020-03-21
</td>
<td align="right">
24513
</td>
<td align="right">
360
</td>
<td align="right">
0.000
</td>
<td align="right">
0.00000
</td>
<td align="right">
0.00000
</td>
<td align="right">
55.57143
</td>
</tr>
<tr class="even">
<td align="left">
2020-03-22
</td>
<td align="right">
33046
</td>
<td align="right">
457
</td>
<td align="right">
4204.714
</td>
<td align="right">
55.57143
</td>
<td align="right">
55.57143
</td>
<td align="right">
69.57143
</td>
</tr>
<tr class="odd">
<td align="left">
2020-03-23
</td>
<td align="right">
43476
</td>
<td align="right">
578
</td>
<td align="right">
5565.143
</td>
<td align="right">
69.57143
</td>
<td align="right">
69.57143
</td>
<td align="right">
95.28571
</td>
</tr>
<tr class="even">
<td align="left">
2020-03-24
</td>
<td align="right">
53906
</td>
<td align="right">
784
</td>
<td align="right">
6857.571
</td>
<td align="right">
95.28571
</td>
<td align="right">
95.28571
</td>
<td align="right">
127.28571
</td>
</tr>
</tbody>

</table>
<p>
…etc up to 40
</p>
<p>
Now we start the job of actually building the linear models and seeing the real power of the tidy modeling framework. Since we have our lead days in columns we revert back to long-form data. For each date we have a case count and 40 lead days with the corresponding death count. As will be seen below, the decline in the fatality rate has been non-linear, so we use a second-order polynomial to regress the <code>date</code> variable.
</p>
<p>
Our workflow looks like this:
</p>
<ol style="list-style-type: decimal">
<li>
Create the lags using <code>tk_augment_lag</code> (above).
</li>
<li>
<code>pivot</code> to long form.
</li>
<li>
<code>nest</code> the data by lead day and state.
</li>
<li>
<code>map</code> the data set for each lead day to a regression model.
</li>
<li>
Pull out the adjusted R-Squared using <code>glance</code> for each model to determine the best fit lead time.
</li>
</ol>
<p>
The result is a data frame with our lead times, the nested raw data, model and R-squared for each lead time.
</p>
<pre class="sourceCode r code-with-copy"><code># make long form to nest
# initialize models data frame
models &lt;- us_lags %&gt;% ungroup %&gt;% 
  pivot_longer(cols = contains("lead"),
               names_to = "lead",
               values_to = "led_deaths") %&gt;% 
  select(date,cases_7day,lead,led_deaths) %&gt;% 
  mutate(lead = as.numeric(str_remove(lead,"deaths_7day_lead"))) %&gt;% 

  nest(data=c(date,cases_7day,led_deaths)) %&gt;% 
  # Run a regression on lagged cases and date vs deaths
  mutate(model = map(data,
                     function(df) 
                       lm(led_deaths~cases_7day+poly(date,2),data = df)))

# Add regression coefficient
# get adjusted r squared
models &lt;- models %&gt;% 
  mutate(adj_r = map(model,function(x) glance(x) %&gt;% 
                       pull(adj.r.squared))
         %&gt;% unlist)
models</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<pre><code>## # A tibble: 41 x 4
##     lead data               model  adj_r
##    &lt;dbl&gt; &lt;list&gt;             &lt;list&gt; &lt;dbl&gt;
##  1     0 &lt;tibble [218 x 3]&gt; &lt;lm&gt;   0.164
##  2     1 &lt;tibble [218 x 3]&gt; &lt;lm&gt;   0.187
##  3     2 &lt;tibble [218 x 3]&gt; &lt;lm&gt;   0.212
##  4     3 &lt;tibble [218 x 3]&gt; &lt;lm&gt;   0.241
##  5     4 &lt;tibble [218 x 3]&gt; &lt;lm&gt;   0.272
##  6     5 &lt;tibble [218 x 3]&gt; &lt;lm&gt;   0.307
##  7     6 &lt;tibble [218 x 3]&gt; &lt;lm&gt;   0.343
##  8     7 &lt;tibble [218 x 3]&gt; &lt;lm&gt;   0.383
##  9     8 &lt;tibble [218 x 3]&gt; &lt;lm&gt;   0.424
## 10     9 &lt;tibble [218 x 3]&gt; &lt;lm&gt;   0.467
## # ... with 31 more rows</code></pre>
<p>
To decide the best-fit lead time we choose the model with the highest R-squared.
</p>
<pre class="sourceCode r code-with-copy"><code># Show model fit by lead time
# make predictions using best model
best_fit &lt;- models %&gt;% 
  summarize(adj_r = max(adj_r)) %&gt;% 
  left_join(models,by= "adj_r")

models %&gt;%
  ggplot(aes(lead,adj_r)) + geom_line() +
  labs(subtitle = paste("Best fit lead =",best_fit$lead,"days"),
       title = "Model Fit By Lag Days",
       x = "Lead Time in Days for Deaths",
       caption = "Source: NY Times, Arthur Steinmetz",
       y= "Adjusted R-squared")</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/unnamed-chunk-6-1.png" width="672"> We can have some confidence that we are not overfitting the <code>date</code> variable because the significance of the case count remains. With a high enough degree polynomial on the <code>date</code> variable, cases would vanish in importance.
</p>
<pre class="sourceCode r code-with-copy"><code>best_fit$model[[1]] %&gt;% tidy()</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<pre><code>## # A tibble: 4 x 5
##   term             estimate  std.error statistic  p.value
##   &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)      436.      38.0           11.5 4.21e-24
## 2 cases_7day         0.0167   0.000993      16.8 5.45e-41
## 3 poly(date, 2)1 -7306.     227.           -32.2 5.87e-84
## 4 poly(date, 2)2  4511.     167.            26.9 1.02e-70</code></pre>
</section>
<section id="make-predictions" class="level1">
<h1>
Make Predictions
</h1>
<p>
The best-fit lead time is 23 days but let’s use <code>predict</code> to see how well our model fits to the actual deaths.
</p>
<pre class="sourceCode r code-with-copy"><code># ------------------------------------------
# see how well our model predicts
# Function to create prediction plot
show_predictions &lt;- function(single_model,n.ahead){
  predicted_deaths = predict(single_model$model[[1]],newdata = us)
  date = seq.Date(from=min(us$date) + n.ahead,to=max(us$date) + n.ahead,by=1)
  display = full_join(us,tibble(date,predicted_deaths))

  gg &lt;- display %&gt;% 
    pivot_longer(cols = where(is.numeric)) %&gt;% 
    filter(name %in% c("deaths_7day","predicted_deaths")) %&gt;% 
    ggplot(aes(date,value,color=name)) + geom_line() +
    labs(title="Actual vs. Predicted Deaths",
         x = "Date", 
         y = "Count",
         caption = "Source: NY Times, Arthur Steinmetz")
  gg
}

show_predictions(best_fit,best_fit$lead)</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/unnamed-chunk-8-1.png" width="672">
</p>
<p>
This is a satisfying result, but sadly shows deaths about to spike. This is despite accounting for the improvements in treatment outcomes we’ve accomplished over the past several months. The 23-day lead time model shows a 1.7% mortality rate over the whole length of observations but conditioned on deaths falling steadily over time.
</p>
</section>
<section id="declining-mortality-rate" class="level1">
<h1>
Declining Mortality Rate
</h1>
<p>
Once we’ve settled on the appropriate lag time, we can look at the fatality rate per identified case. This is but one possible measure of fatality rate, certainly not THE fatality rate. Testing rate, positivity rate and others variables will affect this measure. We also assume our best-fit lag is stable over time so take the result with a grain of salt. The takeaway should be how it is declining, not exactly what it is.
</p>
<p>
Early on, only people who were very sick or met strict criteria were tested so, of course, fatality rates (on this metric) were much, much higher. To minimize this we start our measure at the middle of April.
</p>
<p>
Sadly, we see that fatality rates are creeping up again.
</p>
<pre class="sourceCode r code-with-copy"><code>fatality &lt;- best_fit$data[[1]] %&gt;% 
  filter(cases_7day &gt; 0) %&gt;%
  filter(date &gt; as.Date("2020-04-15")) %&gt;%
  mutate(rate = led_deaths/cases_7day)

fatality %&gt;% ggplot(aes(date,rate)) + geom_line() + 
  geom_smooth() +
  labs(x="Date",y="Fatality Rate",
       title = "Fatality Rates are Creeping Up",
       subtitle = "Fatality Rate as a Percentage of Lagged Cases",
       caption = "Source: NY Times, Arthur Steinmetz") +
  scale_y_continuous(labels = scales::percent)</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/unnamed-chunk-9-1.png" width="672">
</p>
</section>
<section id="state-level-analysis" class="level1">
<h1>
State-Level Analysis
</h1>
<p>
One problem with the national model is each state saw the arrival of the virus at different times, which suggests there might also be different relationships between cases and deaths. Looking at a few selected states illustrates this.
</p>
<pre class="sourceCode r code-with-copy"><code># ------------------------------------------
# state by state analysis

state_subset &lt;- c("New York","Texas","California","Ohio")

# illustrate selected states
us_states %&gt;% 
  filter(state %in% state_subset) %&gt;% 
  ggplot(aes(date,cases_7day)) + geom_line(color="orange") +
  facet_wrap(~state,scales = "free") +
  theme(legend.position = "none") +
  geom_line(aes(y=deaths_7day*coeff),color="red") +
  scale_y_continuous(labels = scales::comma,
                     name = "Cases",
                     sec.axis = sec_axis(deaths_7day~./coeff,
                                         name="Deaths",
                                         labels = scales::comma)) +
  theme(
    axis.title.y = element_text(color = "orange", size=13),
    axis.title.y.right = element_text(color = "red", size=13)
  ) +
  labs(title =  "U.S. Cases vs. Deaths",
       subtitle = "7-Day Average",
       caption = "Source: NY Times, Arthur Steinmetz",
       x = "Date")</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/unnamed-chunk-10-1.png" width="576">
</p>
<p>
In particular we note New York, where the virus arrived early and circulated undetected for weeks. Testing was rare and we did not know much about the course of the disease so the death toll was much worse. Tests were often not conducted until the disease was in advanced stages so we would expect the lag to be shorter.
</p>
<p>
In Texas, the virus arrived later. There it looks like the consequences of the first wave were less dire and the lag was longer.
</p>
</section>
<section id="run-state-models" class="level1">
<h1>
Run State Models
</h1>
<p>
Now we can run the same workflow we used above over the state-by-state data. Our data set is much larger because we have a full set of lags for each state but building our data frame of list columns is just as easy.
</p>
<p>
Looking at the lags by state shows similar results to the national model, on average, as we assume, but the dispersion is large. Early in the pandemic, in New York, cases were diagnosed only for people who were already sick so the lead time before death was much shorter.
</p>
<pre class="sourceCode r code-with-copy"><code># create lags
us_states_lags &lt;- us_states %&gt;%
  # create lags by day
  tk_augment_lags(deaths_7day,.lags = -max_lead:0,.names="auto") %&gt;% 
  {.}
# fix names to remove minus sign
names(us_states_lags) &lt;- names(us_states_lags) %&gt;% str_replace_all("lag-","lead")

# make long form to nest
# initialize models data frame
models_st &lt;- us_states_lags %&gt;% ungroup %&gt;% 
  pivot_longer(cols = contains("lead"),
               names_to = "lead",
               values_to = "led_deaths") %&gt;% 
  select(state,date,cases_7day,lead,led_deaths) %&gt;% 
  mutate(lead = as.numeric(str_remove(lead,"deaths_7day_lead"))) %&gt;% 
  {.}

# make separate tibbles for each regression
models_st &lt;- models_st %&gt;% 
  nest(data=c(date,cases_7day,led_deaths)) %&gt;% 
  arrange(lead)

#Run a linear regression on lagged cases and date vs deaths
models_st &lt;- models_st %&gt;% 
  mutate(model = map(data,
                     function(df) 
                       lm(led_deaths~cases_7day+poly(date,2),data = df)))


# Add regression coefficient
# get adjusted r squared
models_st &lt;- models_st %&gt;% 
  mutate(adj_r = map(model,function(x) glance(x) %&gt;% 
                       pull(adj.r.squared))
         %&gt;% unlist)

models_st %&gt;%
  filter(state %in% state_subset) %&gt;% 
  ggplot(aes(lead,adj_r)) + geom_line() +
  facet_wrap(~state) +
  labs(title = "Best Fit Lead Time",
       caption = "Source: NY Times, Arthur Steinmetz")</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/unnamed-chunk-11-1.png" width="576">
</p>
<p>
To see how the fit looks for the data set as a whole we look at a histogram of all the state R-squareds. We see many of the state models have a worse accuracy than the national model.
</p>
<pre class="sourceCode r code-with-copy"><code># best fit lag by state
best_fit_st &lt;- models_st %&gt;% 
  group_by(state) %&gt;% 
  summarize(adj_r = max(adj_r)) %&gt;% 
  left_join(models_st)

best_fit_st %&gt;% ggplot(aes(adj_r)) + 
  geom_histogram(bins = 10,color="white") +
  geom_vline(xintercept = best_fit$adj_r[[1]],color="red") +
  annotate(geom="text",x=0.75,y=18,label="Adj-R in National Model") +
  labs(y = "State Count",
       x="Adjusted R-Squared",
       title = "Goodness of Fit of State Models",
       caption = "Source:NY Times,Arthur Steinmetz")</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/unnamed-chunk-12-1.png" width="672">
</p>
<p>
There are vast differences in the best-fit lead times across the states but the distribution is in agreement with our national model.
</p>
<pre class="sourceCode r code-with-copy"><code>best_fit_st %&gt;% ggplot(aes(lead)) + 
  geom_histogram(binwidth = 5,color="white") +
  scale_y_continuous(labels = scales::label_number(accuracy = 1)) +
  geom_vline(xintercept = best_fit$lead[[1]],color="red") +
  annotate(geom="text",x=best_fit$lead[[1]]+7,y=10,label="Lead in National Model") +
  labs(y = "State Count",
    x="Best Fit Model Days from Case to Death",
    title = "COVID-19 Lag Time From Cases to Death",
    caption = "Source:NY Times,Arthur Steinmetz")</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/unnamed-chunk-13-1.png" width="672">
</p>
</section>
<section id="validate-with-individual-case-data-from-ohio" class="level1">
<h1>
Validate with Individual Case Data from Ohio
</h1>
<p>
This whole exercise has involved proxying deaths by time and quantity of positive tests. Ideally, we should look at longitudinal data which follows each individual. The state of Ohio provides that so we’ll look at just this one state to provide a reality check on the foregoing analysis. In our proxy model, Ohio shows a best-fit lead time of 31 days, which is much longer than our national-level model.
</p>
<pre class="sourceCode r code-with-copy"><code># ----------------------------------------------------
best_fit_st %&gt;% select(-data,-model) %&gt;% filter(state == "Ohio") %&gt;% kable()</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>

<table class="table">
<thead>
<tr class="header">
<th align="left">
state
</th>
<th align="right">
adj_r
</th>
<th align="right">
lead
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">
Ohio
</td>
<td align="right">
0.7548416
</td>
<td align="right">
31
</td>
</tr>
</tbody>

</table>
<p>
The caveat here is the NY Times data uses the “case” date which is presumably the date a positive test is recorded. The Ohio data uses “onset” date, which is the date the “illness began.” That is not necessarily the same as the test date.
</p>
<pre class="sourceCode r code-with-copy"><code># source: https://coronavirus.ohio.gov/static/dashboards/COVIDSummaryData.csv
ohio_raw &lt;- read_csv("https://coronavirus.ohio.gov/static/dashboards/COVIDSummaryData.csv", 
                     col_types = cols(`Admission Date` = col_date(format = "%m/%d/%Y"), 
                                      `Date Of Death` = col_date(format = "%m/%d/%Y"), 
                                      `Onset Date` = col_date(format = "%m/%d/%Y")))

# helper function to fix column names to best practice
fix_df_colnames &lt;- function(df){
  names(df)&lt;-names(df) %&gt;% 
    str_replace_all(c(" " = "_" , "," = "" )) %&gt;% 
    tolower()
  return(df)
}

# clean up the data
ohio &lt;- ohio_raw %&gt;% 
  rename(death_count = `Death Due to Illness Count`) %&gt;% 
  filter(County != "Grand Total") %&gt;%
  fix_df_colnames() %&gt;% 
  # data not clean before middle of march
  filter(onset_date &gt;= cutoff_start)</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
How comparable are these data sets? Let’s compare the NY Times case count and dates to the Ohio “Illness Onset” dates.
</p>
<pre class="sourceCode r code-with-copy"><code># create rolling average function
mean_roll_7 &lt;- slidify(mean, .period = 7, .align = "right")

comps &lt;- ohio %&gt;% 
  group_by(onset_date) %&gt;% 
  summarise(OH = sum(case_count),.groups = "drop") %&gt;%
  mutate(OH = mean_roll_7(OH)) %&gt;% 
  ungroup() %&gt;% 
  mutate(state = "Ohio") %&gt;% 
  rename(date=onset_date) %&gt;% 
  left_join(us_states,by=c("date","state")) %&gt;% 
  transmute(date,OH,NYTimes = cases_7day)

comps %&gt;% 
  pivot_longer(c("OH","NYTimes"),names_to = "source",values_to = "count") %&gt;%  
  ggplot(aes(date,count,color=source)) + geom_line() +
  labs(title =  "Case Counts from Different Sources",
       caption = "Source: State of Ohio, NY Times",
       subtitle = "NY Times and State of Ohio",
       x = "Date",
       y = "Daily Case Count (7-day Rolling Average)")</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/unnamed-chunk-16-1.png" width="672"> We clearly see the numbers line up almost exactly but the Ohio data runs about 4 days ahead of the NY Times data.
</p>
<p>
For each individual death, we subtract the onset date from the death date. Then we aggregate the county-level data to statewide and daily data to weekly. Then take the weekly mean of deaths.
</p>
<pre class="sourceCode r code-with-copy"><code># aggregate the data to weekly
ohio &lt;- ohio %&gt;% 
  mutate(onset_to_death = as.numeric(date_of_death - onset_date),
         onset_year = year(onset_date),
         onset_week = epiweek(onset_date))


onset_to_death &lt;- ohio %&gt;%
  filter(death_count &gt; 0) %&gt;% 
  group_by(onset_year,onset_week) %&gt;%
  summarise(death_count_sum = sum(death_count),
            mean_onset_to_death = weighted.mean(onset_to_death,
                                                death_count,
                                                na.rm = TRUE)) %&gt;%
  mutate(date=as.Date(paste(onset_year,onset_week,1),"%Y %U %u")) %&gt;%
  {.}

onset_to_death %&gt;% ggplot(aes(date,death_count_sum)) + geom_col() +
    labs(title =  "Ohio Weekly Deaths",
       caption = "Source: State of Ohio, Arthur Steinmetz",
       subtitle = "Based on Illness Onset Date",
       x = "Date of Illness Onset",
       y = "Deaths")</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/unnamed-chunk-17-1.png" width="672"> When we measure the average lag, we find that it has been fairly stable over time in Ohio. Unfortunately, it differs substantially from our proxy model using untracked cases.
</p>
<pre class="sourceCode r code-with-copy"><code># helper function to annotate plots 
pos_index &lt;- function(index_vec,fraction){
  return(index_vec[round(length(index_vec)*fraction)])
}

avg_lag &lt;- round(mean(onset_to_death$mean_onset_to_death))

onset_to_death %&gt;% ggplot(aes(date,mean_onset_to_death)) + 
  geom_col() +
  geom_hline(yintercept = avg_lag) +
  annotate(geom="text",
           label=paste("Average Lag =",round(avg_lag)),
           y=20,x=pos_index(onset_to_death$date,.8)) +
  labs(x = "Onset Date",
       y = "Mean Onset to Death",
       title = "Ohio Days from Illness Onset Until Death Over Time",
       caption = "Source: State of Ohio, Arthur Steinmetz",
       subtitle = paste("Average =",
                     avg_lag,"Days"))</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/unnamed-chunk-18-1.png" width="672"> Note the drop off at the end of the date range. This is because we don’t yet know the outcome of the most recently recorded cases. Generally, while we have been successful in lowering the fatality rate of this disease, the duration from onset to death for those cases which are fatal has not changed much, at least in Ohio.
</p>
<p>
Since we have the actual number of deaths associated with every onset date we can calculate the “true” fatality rate. As mentioned, the fatality rate of the more recent cases is not yet known. Also the data is too sparse at the front of the series so we cut off the head and the tail of the data.
</p>
<pre class="sourceCode r code-with-copy"><code>ohio_fatality_rate &lt;- ohio %&gt;% 
  group_by(onset_date) %&gt;% 
  summarize(case_count = sum(case_count),
            death_count = sum(death_count),.groups="drop") %&gt;% 
  mutate(fatality_rate = death_count/case_count) %&gt;% 
  mutate(fatality_rate_7day = mean_roll_7(fatality_rate)) %&gt;% 
# filter out most recent cases we we don't know outcome yet
  filter(onset_date &lt; max(onset_date)-30) 

ohio_fatality_rate %&gt;% 
  filter(onset_date &gt; as.Date("2020-04-15")) %&gt;% 
  ggplot(aes(onset_date,fatality_rate_7day)) + geom_line() +
  geom_smooth() +
  labs(x="Illness Onset Date",y="Ohio Fatality Rate",
       caption = "Source: State of Ohio, Arthur Steinmetz",
       title = "Ohio Fatality Rate as a Percentage of Tracked Cases") +
  scale_y_continuous(labels = scales::percent,breaks = seq(0,0.12,by=.01))</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<p>
<img src="img/unnamed-chunk-19-1.png" width="672">
</p>
<p>
The fatality rate in Ohio seems to have been worse than our national model but it is coming down. Again, this result comes from a different methodology than our proxy model.
</p>
</section>
<section id="conclusion" class="level1">
<h1>
Conclusion
</h1>
<p>
Among the vexing aspects of this terrible pandemic is that we don’t know what the gold standard is for treatment and prevention. We are learning as we go. The good news is we ARE learning. For a data analyst the challenge is the evolving relationship of of all of the disparate data. Here we have gotten some insight into the duration between a positive test and mortality. We can’t have high confidence that our proxy model using aggregate cases is strictly accurate because the longitudinal data from Ohio shows a different lag. We have clearly seen that mortality has been declining but our model suggests that death will nonetheless surge along with the autumn surge in cases.
</p>
<p>
What are the further avenues for modeling? There is a wealth of data around behavior and demographics with this disease that we don’t fully understand yet. On the analytics side, we might get more sophisticated with our modeling. We have only scratched the surface of the <code>tidymodels</code> framework and we might apply fancier predictive models than linear regression. Is the drop in the fatality rate we saw early in the pandemic real? Only people who were actually sick got tested in the early days. Now, many positive tests are from asymptomatic people. Finally, the disagreement between the case proxy model and the longitudinal data in Ohio shows there is more work to be done.
</p>
</section>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>